title,abstract,socialBlurb,materials,(Optional) Additional Information
"Machine Reasoning for Knowledgeable, Explainable and Inferable Models","Broadly speaking, machine reasoning research aims to build AI systems that can draw new conclusions or solve unseen problems from what they are told (i.e. environment) and already know (i.e. knowledge) by using inference techniques such as induction and deduction. In this tutorial, we will (1) review definitions, key components and characteristics of machine reasoning; (2) introduce typical machine reasoning frameworks, including symbolic reasoning, statistical relational learning, neural-symbolic reasoning and environment-based reasoning; (3) talk about necessary technologies of applying machine reasoning in NLP scenarios, including natural language understanding (NLU), human-computer interaction (HCI), natural language generation (NLG) and model interpretation; (4) show examples of applying machine reasoning techniques in real-world applications; (5) summarize challenges of current methods and discuss possible future directions.","Broadly speaking, machine reasoning research aims to build AI systems that can draw new conclusions or solve unseen problems from what they are told (i.e. environment) and already know (i.e. knowledge) by using inference techniques such as induction and deduction. In this tutorial, we will (1) review definitions, key components and characteristics of machine reasoning; (2) introduce typical machine reasoning frameworks, including symbolic reasoning, statistical relational learning, neural-symbolic reasoning and environment-based reasoning; (3) talk about necessary technologies of applying machine reasoning in NLP scenarios, including natural language understanding (NLU), human-computer interaction (HCI), natural language generation (NLG) and model interpretation; (4) show examples of applying machine reasoning techniques in real-world applications; (5) summarize challenges of current methods and discuss possible future directions.",,
"Representation, Learning and Reasoning on Spatial Language for Downstream NLP Tasks","Understating spatial semantics expressed in natural language can become highly complex in real-world applications. This includes applications of language grounding, navigation, visual question answering, and more generic human-machine interaction and dialogue systems. In many of such downstream tasks, explicit representation of spatial concepts and relationships can improve the capabilities of machine learning models in reasoning and deep language understanding. In this tutorial, we overview the cutting-edge research results and existing challenges related to spatial language understanding including semantic annotations,  existing corpora, symbolic and sub-symbolic representations, qualitative spatial reasoning, spatial common sense, deep and structured learning models.  We discuss the recent results on the above-mentioned applications --that need spatial language learning and reasoning -- and highlight the research gaps and future directions.    
","Understanding spatial language is important in many real-world applications. This includes applications of language grounding, navigation, visual question answering, and more generic human-machine interaction and dialogue systems. In many of such downstream tasks, explicit representation of spatial concepts and relationships can improve the capabilities of machine learning models in reasoning and deep language understanding. In this tutorial, we overview the cutting-edge research results and existing challenges related to spatial language understanding including semantic annotations,  existing corpora, symbolic and sub-symbolic representations, qualitative spatial reasoning, spatial common sense, deep and structured learning models.  We discuss the recent results on the above-mentioned applications --that need spatial language learning and reasoning -- and highlight the research gaps and future directions.    ", https://spatial-language-tutorial.github.io ,
The Amazing World of Neural Language Generation,"Neural Language Generation (NLG) -- using neural network models to generate coherent text -- is among the most promising methods for automated text creation.  Recent years have seen a paradigm shift in neural text generation, caused by the advances in deep contextual language modeling (e.g., LSTMs, GPT, GPT2) and transfer learning (e.g., ELMo, BERT). While these tools have dramatically improved the state of NLG, particularly for low resources tasks, state-of-the-art NLG models still face many challenges: a lack of diversity in generated text, commonsense violations in depicted situations, difficulties in making use of factual information, and difficulties in designing reliable evaluation metrics. In this tutorial, we will present an overview of the current state-of-the-art in neural network architectures, and how they shaped recent research directions in text generation. We will discuss how and why these models succeed/fail at generating coherent text, and provide insights on several applications.","This tutorial presents an overview of the current state-of-the-art in neural network architectures, and how they shaped recent research directions in text generation.",,
Simultaneous Translation,"Simultaneous translation, which performs translation concurrently with the source speech, is widely useful in many scenarios such as international conferences, negotiations, press releases, legal proceedings, and medicine. This problem has long been considered one of the hardest problems in AI and one of its holy grails.
Recently, with rapid improvements in machine translation, speech recognition, and speech synthesis, there has been exciting progress towards simultaneous translation. This tutorial will focus on the design and evaluation of policies for simultaneous translation, to leave attendees with a deep technical understanding of the history, the recent advances, and the remaining challenges in this field.","Simultaneous translation, which performs translation concurrently with the source speech, is widely useful in many scenarios such as international conferences, negotiations, press releases, legal proceedings, and medicine. This problem has long been considered one of the hardest problems in AI and one of its holy grails.
Recently, with rapid improvements in machine translation, speech recognition, and speech synthesis, there has been exciting progress towards simultaneous translation. This tutorial will focus on the design and evaluation of policies for simultaneous translation, to leave attendees with a deep technical understanding of the history, the recent advances, and the remaining challenges in this field.",,
High Performance Natural Language Processing,"Scale has played a central role in the rapid progress natural language processing has enjoyed in recent years. While benchmarks are dominated by ever larger models, efficient hardware use is critical for their widespread adoption and further progress in the field. In this cutting-edge tutorial, we will recapitulate the state-of-the-art in natural language processing with scale in perspective. After establishing these foundations, we will cover a wide range of techniques for improving efficiency, including knowledge distillation, quantization, pruning, more efficient architectures, along with case studies and practical implementation tricks.","Scale has played a central role in the rapid progress natural language processing has enjoyed in recent years. While benchmarks are dominated by ever larger models, efficient hardware use is critical for their widespread adoption and further progress in the field. In this cutting-edge tutorial, we will recapitulate the state-of-the-art in natural language processing with scale in perspective. After establishing these foundations, we will cover a wide range of techniques for improving efficiency, including knowledge distillation, quantization, pruning, more efficient architectures, along with case studies and practical implementation tricks.",,
Interpreting Predictions of NLP Models,"Although neural NLP models are highly expressive and empirically successful, they also systematically fail in counterintuitive ways and are opaque in their decision-making process. This tutorial will provide a background on interpretation techniques, i.e., methods for explaining the predictions of NLP models. We will first situate example-specific interpretations in the context of other ways to understand models (e.g., probing, dataset analyses). Next, we will present a thorough study of example-specific interpretations, including saliency maps, input perturbations (e.g., LIME, input reduction), adversarial attacks, and influence functions. Alongside these descriptions, we will walk through source code that creates and visualizes interpretations for a diverse set of NLP tasks. Finally, we will discuss open problems in the field, e.g., evaluating, extending, and improving interpretation methods.","Neural NLP models fail in counterintuitive ways and are opaque in their decision-making process. This tutorial will describe methods for interpreting the predictions of complex NLP models. We will first situate example-specific interpretations in the context of other ways to understand models (e.g., probing, dataset analyses). Next, we will present a thorough study of example-specific interpretations, including saliency maps, input perturbations, and influence functions. Alongside these descriptions, we will walk through easy-to-use source code that creates and visualizes interpretations for a diverse set of tasks. We will conclude with a discussion of open problems in the field.",https://www.ericswallace.com/interpretability,
"Fact-Checking, Fake News, Propaganda, and Media Bias: Truth Seeking in the Post-Truth Era","The rise of social media has democratized content creation and has made it easy for anybody to share and to spread information online. On the positive side, this has given rise to citizen journalism, thus enabling much faster dissemination of information compared to what was possible with newspapers, radio, and TV. On the negative side, stripping traditional media from their gate-keeping role has left the public unprotected against the spread of disinformation, which could now travel at breaking-news speed over the same democratic channel. This situation gave rise to the proliferation of false information specifically created to affect individual people's beliefs, and ultimately to influence major events such as political elections; it also set the dawn of the Post-Truth Era, where appeal to emotions has become more important than the truth. More recently, with the emergence of the COVID-19 pandemic, a new blending of medical and political misinformation and disinformation has given rise to the first global infodemic. Limiting the impact of these negative developments has become a major focus for journalists, social media companies, and regulatory authorities. 

The tutorial offers an overview of the emerging and inter-connected research areas of fact-checking, misinformation, disinformation, “fake news”, propaganda, and media bias detection, with focus on text and on computational approaches. It further explores the general fact-checking pipeline and important elements thereof such as check-worthiness estimation, spotting previous fact-checked claims, stance detection, source reliability estimation, and detecting malicious users in social media. Finally, it covers some recent developments such as the emergence of large-scale pre-trained language models, and the challenges and opportunities they offer.","Fact-Checking, Fake News, Propaganda, and Media Bias: Truth Seeking in the Post-Truth Era. The tutorial offers an overview of the emerging and inter-connected research areas of fact-checking, misinformation, disinformation, “fake news”, propaganda, and media bias detection, with focus on text and on computational approaches. It further explores the general fact-checking pipeline and important elements thereof such as check-worthiness estimation, spotting previous fact-checked claims, stance detection, source reliability estimation, and detecting malicious users in social media. Finally, it covers some recent developments such as the emergence of large-scale pre-trained language models, and the challenges and opportunities they offer. ",https://propaganda.qcri.org/emnlp20-tutorial,